"""
æ•¸æ“šåˆä½µèˆ‡æ¸…æ´—æ¨¡çµ„

æ•´åˆ GitLab API å’Œ Git æœ¬åœ°æ•¸æ“šï¼Œå»ºç«‹é–‹ç™¼è€…çµ±ä¸€èº«ä»½æ˜ å°„ï¼Œä¸¦é€²è¡Œæ•¸æ“šæ¸…æ´—ã€‚
"""

import re
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple
import pandas as pd
from tqdm import tqdm

from config.analysis_config import ExclusionConfig


class DataMerger:
    """æ•¸æ“šåˆä½µèˆ‡æ¸…æ´—å™¨"""

    def __init__(self, input_dir: Optional[str] = None, output_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–åˆä½µå™¨

        Args:
            input_dir: è¼¸å…¥ç›®éŒ„ï¼ˆraw æ•¸æ“šï¼‰ï¼Œé è¨­ç‚º scripts/output/raw/
            output_dir: è¼¸å‡ºç›®éŒ„ï¼ˆprocessed æ•¸æ“šï¼‰ï¼Œé è¨­ç‚º scripts/output/processed/
        """
        if input_dir:
            self.input_dir = Path(input_dir)
        else:
            self.input_dir = Path(__file__).parent.parent / "output" / "raw"

        if output_dir:
            self.output_dir = Path(output_dir)
        else:
            self.output_dir = Path(__file__).parent.parent / "output" / "processed"

        self.output_dir.mkdir(parents=True, exist_ok=True)

    # ==================== é–‹ç™¼è€…èº«ä»½çµ±ä¸€ ====================

    def unify_developers(
        self, manual_mapping: Optional[Dict[str, str]] = None
    ) -> pd.DataFrame:
        """
        çµ±ä¸€é–‹ç™¼è€…èº«ä»½ï¼ˆå»ºç«‹ username <-> email <-> name æ˜ å°„è¡¨ï¼‰

        Args:
            manual_mapping: æ‰‹å‹•æ˜ å°„ï¼ˆemail -> canonical_emailï¼‰

        Returns:
            çµ±ä¸€é–‹ç™¼è€…èº«ä»½ DataFrame
        """
        print("\nğŸ” çµ±ä¸€é–‹ç™¼è€…èº«ä»½...")

        developers_map = {}  # email -> {username, name, commit_count}

        # 1. å¾ Git æœ¬åœ°æ•¸æ“šå–å¾—é–‹ç™¼è€…
        git_devs_file = self.input_dir / "git_developers.csv"
        if git_devs_file.exists():
            git_devs = pd.read_csv(git_devs_file)
            for _, row in git_devs.iterrows():
                email = row["email"].lower()
                if not self._is_bot(row["name"], email):
                    if email not in developers_map:
                        developers_map[email] = {
                            "username": "",
                            "name": row["name"],
                            "email": email,
                            "commit_count": row["commit_count"],
                            "source": "git",
                        }

        # 2. å¾ GitLab MR æ•¸æ“šè£œå…… username
        mr_file = self.input_dir / "gitlab_merge_requests.csv"
        if mr_file.exists():
            mrs = pd.read_csv(mr_file)
            for _, row in mrs.iterrows():
                email = str(row.get("author_email", "")).lower()
                username = row.get("author_username", "")
                name = row.get("author_name", "")

                if email and not self._is_bot(name, email):
                    if email in developers_map:
                        if not developers_map[email]["username"]:
                            developers_map[email]["username"] = username
                    else:
                        developers_map[email] = {
                            "username": username,
                            "name": name,
                            "email": email,
                            "commit_count": 0,
                            "source": "gitlab_mr",
                        }

        # 3. å¾ GitLab Commits æ•¸æ“šè£œå……
        gitlab_commits_file = self.input_dir / "gitlab_commits.csv"
        if gitlab_commits_file.exists():
            commits = pd.read_csv(gitlab_commits_file)
            for _, row in commits.iterrows():
                email = str(row.get("author_email", "")).lower()
                name = row.get("author_name", "")

                if email and email in developers_map and not self._is_bot(name, email):
                    developers_map[email]["commit_count"] = (
                        developers_map[email].get("commit_count", 0) + 1
                    )

        # 4. æ‡‰ç”¨æ‰‹å‹•æ˜ å°„
        if manual_mapping:
            print(f"   æ‡‰ç”¨ {len(manual_mapping)} å€‹æ‰‹å‹•æ˜ å°„")
            merged_map = {}
            for email, canonical_email in manual_mapping.items():
                email = email.lower()
                canonical_email = canonical_email.lower()

                if email in developers_map:
                    if canonical_email not in merged_map:
                        merged_map[canonical_email] = developers_map[email]
                    else:
                        # åˆä½µ commit_count
                        merged_map[canonical_email]["commit_count"] += developers_map[
                            email
                        ]["commit_count"]

            developers_map.update(merged_map)

        # è½‰æ›ç‚º DataFrame
        developers = []
        for email, info in developers_map.items():
            developers.append(
                {
                    "email": email,
                    "username": info.get("username", ""),
                    "name": info.get("name", ""),
                    "commit_count": info.get("commit_count", 0),
                    "source": info.get("source", ""),
                }
            )

        df = pd.DataFrame(developers)
        df = df.sort_values("commit_count", ascending=False)

        # å„²å­˜
        output_file = self.output_dir / "unified_developers.csv"
        df.to_csv(output_file, index=False, encoding="utf-8-sig")
        print(f"âœ… çµ±ä¸€é–‹ç™¼è€…èº«ä»½å·²å„²å­˜: {output_file} (å…± {len(df)} ä½)")

        return df

    def _is_bot(self, name: str, email: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚º Bot è³¬è™Ÿ"""
        name_lower = name.lower() if name else ""
        email_lower = email.lower() if email else ""

        return any(
            bot.lower() in name_lower or bot.lower() in email_lower
            for bot in ExclusionConfig.EXCLUDED_BOTS
        )

    # ==================== Commit æ•¸æ“šåˆä½µ ====================

    def merge_commits(self) -> pd.DataFrame:
        """
        åˆä½µ GitLab API å’Œ Git æœ¬åœ°çš„ Commit æ•¸æ“š

        Returns:
            åˆä½µå¾Œçš„ Commit DataFrame
        """
        print("\nğŸ” åˆä½µ Commit æ•¸æ“š...")

        commits_list = []

        # 1. è®€å– Git æœ¬åœ°æ•¸æ“šï¼ˆæ›´è©³ç´°ï¼‰
        git_commits_file = self.input_dir / "git_commits.csv"
        if git_commits_file.exists():
            git_commits = pd.read_csv(git_commits_file)
            git_commits["source"] = "git_local"
            commits_list.append(git_commits)
            print(f"   Git æœ¬åœ° Commits: {len(git_commits)}")

        # 2. è®€å– GitLab API æ•¸æ“šï¼ˆè£œå……ï¼‰
        gitlab_commits_file = self.input_dir / "gitlab_commits.csv"
        if gitlab_commits_file.exists():
            gitlab_commits = pd.read_csv(gitlab_commits_file)
            gitlab_commits["source"] = "gitlab_api"
            commits_list.append(gitlab_commits)
            print(f"   GitLab API Commits: {len(gitlab_commits)}")

        if not commits_list:
            print("âš ï¸ æ²’æœ‰æ‰¾åˆ° Commit æ•¸æ“šæª”æ¡ˆ")
            return pd.DataFrame()

        # åˆä½µï¼ˆä»¥ commit_sha ç‚ºä¸»éµå»é‡ï¼Œå„ªå…ˆä½¿ç”¨ git_localï¼‰
        df = pd.concat(commits_list, ignore_index=True)
        df = df.drop_duplicates(subset=["commit_sha"], keep="first")

        # æ¸…æ´—ï¼šæ’é™¤ç‰¹å®šæ¨¡å¼çš„ Commit
        df = self._clean_commits(df)

        # å„²å­˜
        output_file = self.output_dir / "all_commits_merged.csv"
        df.to_csv(output_file, index=False, encoding="utf-8-sig")
        print(f"âœ… åˆä½µ Commit æ•¸æ“šå·²å„²å­˜: {output_file} (å…± {len(df)} ç­†)")

        return df

    def _clean_commits(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…æ´— Commit æ•¸æ“š"""
        original_count = len(df)

        # æ’é™¤ç‰¹å®šæ¨¡å¼çš„ Commit Message
        for pattern in ExclusionConfig.EXCLUDED_COMMIT_PATTERNS:
            df = df[~df["title"].str.match(pattern, na=False)]

        cleaned_count = len(df)
        if cleaned_count < original_count:
            print(f"   æ’é™¤ {original_count - cleaned_count} å€‹ Commitï¼ˆMergeã€WIP ç­‰ï¼‰")

        return df

    # ==================== Review Comments åˆä½µ ====================

    def merge_review_comments(self) -> pd.DataFrame:
        """
        åˆä½µ Review Comments æ•¸æ“š

        Returns:
            åˆä½µå¾Œçš„ Review Comments DataFrame
        """
        print("\nğŸ” åˆä½µ Review Comments æ•¸æ“š...")

        comments_file = self.input_dir / "gitlab_review_comments.csv"
        if not comments_file.exists():
            print("âš ï¸ æ²’æœ‰æ‰¾åˆ° Review Comments æ•¸æ“šæª”æ¡ˆ")
            return pd.DataFrame()

        df = pd.read_csv(comments_file)

        # æ¸…æ´—ï¼šæ’é™¤ç³»çµ±è¨Šæ¯ï¼ˆå·²åœ¨æ”¶é›†æ™‚è™•ç†ï¼‰
        # åˆ†é¡ Comment é¡å‹ï¼ˆLGTM-only vs æœ‰å»ºè­°ï¼‰
        df = self._classify_comments(df)

        # å„²å­˜
        output_file = self.output_dir / "all_reviews_merged.csv"
        df.to_csv(output_file, index=False, encoding="utf-8-sig")
        print(f"âœ… åˆä½µ Review Comments æ•¸æ“šå·²å„²å­˜: {output_file} (å…± {len(df)} ç­†)")

        return df

    def _classify_comments(self, df: pd.DataFrame) -> pd.DataFrame:
        """åˆ†é¡ Review Comment é¡å‹"""
        from config.analysis_config import CodeReviewConfig

        def is_lgtm_only(body: str) -> bool:
            """åˆ¤æ–·æ˜¯å¦ç‚º LGTM-only è©•è«–"""
            if not body or len(body.strip()) < 5:
                return True

            body_lower = body.lower()
            return any(keyword in body_lower for keyword in CodeReviewConfig.LGTM_KEYWORDS)

        df["is_lgtm_only"] = df["body"].apply(is_lgtm_only)
        df["has_suggestion"] = ~df["is_lgtm_only"]

        return df

    # ==================== æª”æ¡ˆè®Šæ›´æ¸…æ´— ====================

    def clean_file_changes(self) -> pd.DataFrame:
        """
        æ¸…æ´—æª”æ¡ˆè®Šæ›´æ•¸æ“šï¼ˆæ’é™¤è‡ªå‹•ç”Ÿæˆæª”æ¡ˆï¼‰

        Returns:
            æ¸…æ´—å¾Œçš„æª”æ¡ˆè®Šæ›´ DataFrame
        """
        print("\nğŸ” æ¸…æ´—æª”æ¡ˆè®Šæ›´æ•¸æ“š...")

        file_changes_file = self.input_dir / "git_file_changes.csv"
        if not file_changes_file.exists():
            print("âš ï¸ æ²’æœ‰æ‰¾åˆ°æª”æ¡ˆè®Šæ›´æ•¸æ“šæª”æ¡ˆ")
            return pd.DataFrame()

        df = pd.read_csv(file_changes_file)
        original_count = len(df)

        # æ’é™¤è‡ªå‹•ç”Ÿæˆçš„æª”æ¡ˆ
        def should_exclude(file_path: str) -> bool:
            """åˆ¤æ–·æª”æ¡ˆæ˜¯å¦æ‡‰è©²è¢«æ’é™¤"""
            if not file_path:
                return True

            for pattern in ExclusionConfig.EXCLUDED_FILE_PATTERNS:
                # ç°¡å–®çš„ glob æ¨¡å¼åŒ¹é…
                if "*" in pattern:
                    # è½‰æ›ç‚ºæ­£å‰‡è¡¨é”å¼
                    regex_pattern = pattern.replace("*", ".*")
                    if re.match(regex_pattern, file_path):
                        return True
                else:
                    # ç²¾ç¢ºåŒ¹é…
                    if pattern in file_path:
                        return True

            return False

        df = df[~df["file_path"].apply(should_exclude)]

        cleaned_count = len(df)
        if cleaned_count < original_count:
            print(
                f"   æ’é™¤ {original_count - cleaned_count} å€‹æª”æ¡ˆè®Šæ›´ï¼ˆlock æª”æ¡ˆã€dist/ ç­‰ï¼‰"
            )

        # å„²å­˜
        output_file = self.output_dir / "file_changes_cleaned.csv"
        df.to_csv(output_file, index=False, encoding="utf-8-sig")
        print(f"âœ… æ¸…æ´—æª”æ¡ˆè®Šæ›´æ•¸æ“šå·²å„²å­˜: {output_file} (å…± {len(df)} ç­†)")

        return df

    # ==================== å®Œæ•´åˆä½µèˆ‡æ¸…æ´— ====================

    def process_all(
        self, manual_developer_mapping: Optional[Dict[str, str]] = None
    ) -> Dict[str, pd.DataFrame]:
        """
        åŸ·è¡Œå®Œæ•´çš„æ•¸æ“šåˆä½µèˆ‡æ¸…æ´—æµç¨‹

        Args:
            manual_developer_mapping: æ‰‹å‹•é–‹ç™¼è€…æ˜ å°„

        Returns:
            åŒ…å«æ‰€æœ‰è™•ç†å¾Œæ•¸æ“šçš„å­—å…¸
        """
        print("=" * 60)
        print("é–‹å§‹æ•¸æ“šåˆä½µèˆ‡æ¸…æ´—")
        print("=" * 60)

        results = {}

        # 1. çµ±ä¸€é–‹ç™¼è€…èº«ä»½
        results["developers"] = self.unify_developers(manual_developer_mapping)

        # 2. åˆä½µ Commits
        results["commits"] = self.merge_commits()

        # 3. åˆä½µ Review Comments
        results["reviews"] = self.merge_review_comments()

        # 4. æ¸…æ´—æª”æ¡ˆè®Šæ›´
        results["file_changes"] = self.clean_file_changes()

        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰æ•¸æ“šåˆä½µèˆ‡æ¸…æ´—å®Œæˆï¼")
        print("=" * 60)
        print(f"çµ±ä¸€é–‹ç™¼è€…: {len(results['developers'])} ä½")
        print(f"åˆä½µ Commits: {len(results['commits'])} ç­†")
        print(f"åˆä½µ Reviews: {len(results['reviews'])} ç­†")
        print(f"æ¸…æ´—æª”æ¡ˆè®Šæ›´: {len(results['file_changes'])} ç­†")
        print("=" * 60)

        return results


# æ¸¬è©¦åŠŸèƒ½
if __name__ == "__main__":
    print("=" * 60)
    print("æ•¸æ“šåˆä½µèˆ‡æ¸…æ´—å™¨æ¸¬è©¦")
    print("=" * 60)

    merger = DataMerger()

    # æ¸¬è©¦ï¼šçµ±ä¸€é–‹ç™¼è€…èº«ä»½
    print("\næ¸¬è©¦ï¼šçµ±ä¸€é–‹ç™¼è€…èº«ä»½")
    try:
        developers_df = merger.unify_developers()
        print(f"\nçµ±ä¸€å¾Œé–‹ç™¼è€…æ•¸é‡: {len(developers_df)}")
        if len(developers_df) > 0:
            print("\nå‰ 5 ä½é–‹ç™¼è€…ï¼š")
            print(developers_df.head()[["email", "username", "name", "commit_count"]])
    except Exception as e:
        print(f"âš ï¸ æ¸¬è©¦å¤±æ•—: {e}")

    print("\n" + "=" * 60)
    print("âœ… æ¸¬è©¦å®Œæˆ")
    print("=" * 60)
