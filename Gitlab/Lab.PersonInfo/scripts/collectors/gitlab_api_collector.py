"""
GitLab API æ•¸æ“šæ”¶é›†å™¨

é€é GitLab API æ”¶é›†å°ˆæ¡ˆã€Merge Requestã€Review Commentsã€Commit ç­‰æ•¸æ“šã€‚
"""

import os
import time
import csv
from pathlib import Path
from typing import List, Dict, Optional, Any
from datetime import datetime
from tqdm import tqdm
import pandas as pd
import gitlab
from gitlab.v4.objects import Project, MergeRequest

from config.gitlab_config import get_gitlab_config, get_gitlab_client


class GitLabAPICollector:
    """GitLab API æ•¸æ“šæ”¶é›†å™¨"""

    def __init__(self, output_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–æ”¶é›†å™¨

        Args:
            output_dir: è¼¸å‡ºç›®éŒ„è·¯å¾‘ï¼Œé è¨­ç‚º scripts/output/raw/
        """
        self.config = get_gitlab_config()
        self.gl = get_gitlab_client()

        # è¨­å®šè¼¸å‡ºç›®éŒ„
        if output_dir:
            self.output_dir = Path(output_dir)
        else:
            self.output_dir = Path(__file__).parent.parent / "output" / "raw"

        self.output_dir.mkdir(parents=True, exist_ok=True)

    def _rate_limit_wait(self):
        """API è«‹æ±‚ç¯€æµ"""
        self.config.rate_limit_wait()

    def _retry_on_error(self, func, *args, max_retries: int = 3, **kwargs):
        """
        éŒ¯èª¤é‡è©¦æ©Ÿåˆ¶

        Args:
            func: è¦åŸ·è¡Œçš„å‡½æ•¸
            max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸
            *args, **kwargs: å‡½æ•¸åƒæ•¸

        Returns:
            å‡½æ•¸åŸ·è¡Œçµæœ
        """
        for attempt in range(max_retries):
            try:
                return func(*args, **kwargs)
            except gitlab.exceptions.GitlabError as e:
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 2  # æŒ‡æ•¸é€€é¿
                    print(f"âš ï¸ è«‹æ±‚å¤±æ•—ï¼Œ{wait_time} ç§’å¾Œé‡è©¦... (éŒ¯èª¤: {e})")
                    time.sleep(wait_time)
                else:
                    print(f"âŒ é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œè·³éæ­¤è«‹æ±‚: {e}")
                    raise

    # ==================== å°ˆæ¡ˆæ”¶é›† ====================

    def collect_projects(
        self,
        visibility: Optional[str] = None,
        owned: bool = False,
        include_archived: bool = False,
    ) -> pd.DataFrame:
        """
        æ”¶é›†å°ˆæ¡ˆåˆ—è¡¨

        Args:
            visibility: å¯è¦‹æ€§éæ¿¾ ('public', 'internal', 'private')
            owned: åªå–å¾—è‡ªå·±æ“æœ‰çš„å°ˆæ¡ˆ
            include_archived: æ˜¯å¦åŒ…å«å·²å°å­˜çš„å°ˆæ¡ˆ

        Returns:
            å°ˆæ¡ˆåˆ—è¡¨ DataFrame
        """
        print("\nğŸ” æ”¶é›†å°ˆæ¡ˆåˆ—è¡¨...")

        projects_data = []

        try:
            # å–å¾—å°ˆæ¡ˆåˆ—è¡¨ï¼ˆåˆ†é è™•ç†ï¼‰
            params = {"per_page": 100}
            if visibility:
                params["visibility"] = visibility
            if owned:
                params["owned"] = True
            if not include_archived:
                params["archived"] = False

            projects = self.gl.projects.list(all=True, **params)

            print(f"æ‰¾åˆ° {len(projects)} å€‹å°ˆæ¡ˆ")

            for project in tqdm(projects, desc="è™•ç†å°ˆæ¡ˆ"):
                projects_data.append(
                    {
                        "project_id": project.id,
                        "name": project.name,
                        "path": project.path,
                        "path_with_namespace": project.path_with_namespace,
                        "description": getattr(project, "description", ""),
                        "visibility": getattr(project, "visibility", ""),
                        "created_at": getattr(project, "created_at", ""),
                        "last_activity_at": getattr(project, "last_activity_at", ""),
                        "web_url": project.web_url,
                        "default_branch": getattr(project, "default_branch", "main"),
                        "archived": getattr(project, "archived", False),
                    }
                )
                self._rate_limit_wait()

        except Exception as e:
            print(f"âŒ æ”¶é›†å°ˆæ¡ˆåˆ—è¡¨å¤±æ•—: {e}")
            raise

        # è½‰æ›ç‚º DataFrame
        df = pd.DataFrame(projects_data)

        # å„²å­˜åˆ° CSV
        output_file = self.output_dir / "gitlab_projects.csv"
        df.to_csv(output_file, index=False, encoding="utf-8-sig")
        print(f"âœ… å°ˆæ¡ˆåˆ—è¡¨å·²å„²å­˜: {output_file}")

        return df

    # ==================== Merge Request æ”¶é›† ====================

    def collect_merge_requests(
        self,
        project_ids: Optional[List[int]] = None,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        state: str = "all",
    ) -> pd.DataFrame:
        """
        æ”¶é›† Merge Request æ•¸æ“š

        Args:
            project_ids: å°ˆæ¡ˆ ID åˆ—è¡¨ï¼ŒNone è¡¨ç¤ºæ‰€æœ‰å°ˆæ¡ˆ
            start_date: é–‹å§‹æ—¥æœŸ (ISO 8601 æ ¼å¼ï¼Œä¾‹å¦‚ '2024-01-01')
            end_date: çµæŸæ—¥æœŸ (ISO 8601 æ ¼å¼ï¼Œä¾‹å¦‚ '2024-12-31')
            state: MR ç‹€æ…‹ ('all', 'opened', 'closed', 'merged')

        Returns:
            MR åˆ—è¡¨ DataFrame
        """
        print("\nğŸ” æ”¶é›† Merge Request æ•¸æ“š...")

        # å¦‚æœæ²’æœ‰æŒ‡å®šå°ˆæ¡ˆï¼Œå–å¾—æ‰€æœ‰å°ˆæ¡ˆ
        if project_ids is None:
            projects_df = self.collect_projects()
            project_ids = projects_df["project_id"].tolist()

        mr_data = []

        for project_id in tqdm(project_ids, desc="è™•ç†å°ˆæ¡ˆ MR"):
            try:
                project = self.gl.projects.get(project_id)

                # å–å¾— MR åˆ—è¡¨
                params = {"state": state, "per_page": 100}
                if start_date:
                    params["created_after"] = start_date
                if end_date:
                    params["created_before"] = end_date

                mrs = project.mergerequests.list(all=True, **params)

                for mr in mrs:
                    # åŸºæœ¬è³‡è¨Š
                    mr_info = {
                        "project_id": project_id,
                        "mr_iid": mr.iid,
                        "mr_id": mr.id,
                        "title": mr.title,
                        "description": getattr(mr, "description", ""),
                        "state": mr.state,
                        "created_at": mr.created_at,
                        "updated_at": mr.updated_at,
                        "merged_at": getattr(mr, "merged_at", None),
                        "closed_at": getattr(mr, "closed_at", None),
                        "author_username": mr.author.get("username", ""),
                        "author_name": mr.author.get("name", ""),
                        "author_id": mr.author.get("id", ""),
                        "source_branch": mr.source_branch,
                        "target_branch": mr.target_branch,
                        "web_url": mr.web_url,
                    }

                    # Assignees (å¯èƒ½æœ‰å¤šå€‹)
                    assignees = getattr(mr, "assignees", [])
                    if assignees:
                        mr_info["assignee_usernames"] = ",".join(
                            [a.get("username", "") for a in assignees]
                        )
                    else:
                        mr_info["assignee_usernames"] = ""

                    # Reviewers (å¯èƒ½æœ‰å¤šå€‹)
                    reviewers = getattr(mr, "reviewers", [])
                    if reviewers:
                        mr_info["reviewer_usernames"] = ",".join(
                            [r.get("username", "") for r in reviewers]
                        )
                    else:
                        mr_info["reviewer_usernames"] = ""

                    # çµ±è¨ˆè³‡è¨Š
                    mr_info["upvotes"] = getattr(mr, "upvotes", 0)
                    mr_info["downvotes"] = getattr(mr, "downvotes", 0)
                    mr_info["user_notes_count"] = getattr(mr, "user_notes_count", 0)

                    # Diff çµ±è¨ˆï¼ˆéœ€è¦é¡å¤–è«‹æ±‚ï¼‰
                    try:
                        changes = mr.changes()
                        mr_info["additions"] = sum(
                            c.get("diff", "").count("\n+") for c in changes.get("changes", [])
                        )
                        mr_info["deletions"] = sum(
                            c.get("diff", "").count("\n-") for c in changes.get("changes", [])
                        )
                        mr_info["changed_files"] = len(changes.get("changes", []))
                    except:
                        mr_info["additions"] = 0
                        mr_info["deletions"] = 0
                        mr_info["changed_files"] = 0

                    # Labels
                    labels = getattr(mr, "labels", [])
                    mr_info["labels"] = ",".join(labels) if labels else ""

                    mr_data.append(mr_info)
                    self._rate_limit_wait()

            except gitlab.exceptions.GitlabGetError as e:
                print(f"âš ï¸ ç„¡æ³•å­˜å–å°ˆæ¡ˆ {project_id}: {e}")
                continue
            except Exception as e:
                print(f"âš ï¸ è™•ç†å°ˆæ¡ˆ {project_id} çš„ MR æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue

        # è½‰æ›ç‚º DataFrame
        df = pd.DataFrame(mr_data)

        # å„²å­˜åˆ° CSV
        output_file = self.output_dir / "gitlab_merge_requests.csv"
        df.to_csv(output_file, index=False, encoding="utf-8-sig")
        print(f"âœ… Merge Request æ•¸æ“šå·²å„²å­˜: {output_file} (å…± {len(df)} ç­†)")

        return df

    # ==================== Review Comments æ”¶é›† ====================

    def collect_review_comments(
        self,
        project_ids: Optional[List[int]] = None,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
    ) -> pd.DataFrame:
        """
        æ”¶é›† Review Comments æ•¸æ“š

        Args:
            project_ids: å°ˆæ¡ˆ ID åˆ—è¡¨ï¼ŒNone è¡¨ç¤ºæ‰€æœ‰å°ˆæ¡ˆ
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ

        Returns:
            Review Comments DataFrame
        """
        print("\nğŸ” æ”¶é›† Review Comments æ•¸æ“š...")

        # å¦‚æœæ²’æœ‰æŒ‡å®šå°ˆæ¡ˆï¼Œå–å¾—æ‰€æœ‰å°ˆæ¡ˆ
        if project_ids is None:
            projects_df = self.collect_projects()
            project_ids = projects_df["project_id"].tolist()

        comments_data = []

        for project_id in tqdm(project_ids, desc="è™•ç†å°ˆæ¡ˆ Review Comments"):
            try:
                project = self.gl.projects.get(project_id)

                # å–å¾— MR åˆ—è¡¨
                params = {"state": "all", "per_page": 100}
                if start_date:
                    params["created_after"] = start_date
                if end_date:
                    params["created_before"] = end_date

                mrs = project.mergerequests.list(all=True, **params)

                for mr in mrs:
                    try:
                        # å–å¾— MR çš„æ‰€æœ‰ Notes (Comments)
                        notes = mr.notes.list(all=True)

                        for note in notes:
                            # åªæ”¶é›†éç³»çµ±è¨Šæ¯çš„ notes
                            if not getattr(note, "system", False):
                                comment_info = {
                                    "project_id": project_id,
                                    "mr_iid": mr.iid,
                                    "mr_id": mr.id,
                                    "note_id": note.id,
                                    "author_username": note.author.get("username", ""),
                                    "author_name": note.author.get("name", ""),
                                    "author_id": note.author.get("id", ""),
                                    "body": note.body,
                                    "created_at": note.created_at,
                                    "updated_at": note.updated_at,
                                    "noteable_type": getattr(note, "noteable_type", ""),
                                    "resolvable": getattr(note, "resolvable", False),
                                    "resolved": getattr(note, "resolved", False),
                                }

                                # Diff Note ç›¸é—œè³‡è¨Š
                                if hasattr(note, "position"):
                                    position = note.position
                                    if position:
                                        comment_info["diff_file_path"] = position.get(
                                            "new_path", ""
                                        )
                                        comment_info["diff_line"] = position.get("new_line", "")
                                    else:
                                        comment_info["diff_file_path"] = ""
                                        comment_info["diff_line"] = ""
                                else:
                                    comment_info["diff_file_path"] = ""
                                    comment_info["diff_line"] = ""

                                comments_data.append(comment_info)

                        self._rate_limit_wait()

                    except Exception as e:
                        print(f"âš ï¸ è™•ç† MR {mr.iid} çš„ Comments æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                        continue

            except gitlab.exceptions.GitlabGetError as e:
                print(f"âš ï¸ ç„¡æ³•å­˜å–å°ˆæ¡ˆ {project_id}: {e}")
                continue
            except Exception as e:
                print(f"âš ï¸ è™•ç†å°ˆæ¡ˆ {project_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue

        # è½‰æ›ç‚º DataFrame
        df = pd.DataFrame(comments_data)

        # å„²å­˜åˆ° CSV
        output_file = self.output_dir / "gitlab_review_comments.csv"
        df.to_csv(output_file, index=False, encoding="utf-8-sig")
        print(f"âœ… Review Comments æ•¸æ“šå·²å„²å­˜: {output_file} (å…± {len(df)} ç­†)")

        return df

    # ==================== Commit æ”¶é›† (API ç‰ˆæœ¬) ====================

    def collect_commits(
        self,
        project_ids: Optional[List[int]] = None,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        ref_name: Optional[str] = None,
    ) -> pd.DataFrame:
        """
        æ”¶é›† Commit æ•¸æ“šï¼ˆé€é APIï¼‰

        Args:
            project_ids: å°ˆæ¡ˆ ID åˆ—è¡¨ï¼ŒNone è¡¨ç¤ºæ‰€æœ‰å°ˆæ¡ˆ
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            ref_name: åˆ†æ”¯åç¨±ï¼ˆé è¨­ç‚ºå°ˆæ¡ˆçš„ default branchï¼‰

        Returns:
            Commit åˆ—è¡¨ DataFrame
        """
        print("\nğŸ” æ”¶é›† Commit æ•¸æ“šï¼ˆAPIï¼‰...")

        # å¦‚æœæ²’æœ‰æŒ‡å®šå°ˆæ¡ˆï¼Œå–å¾—æ‰€æœ‰å°ˆæ¡ˆ
        if project_ids is None:
            projects_df = self.collect_projects()
            project_ids = projects_df["project_id"].tolist()

        commit_data = []

        for project_id in tqdm(project_ids, desc="è™•ç†å°ˆæ¡ˆ Commits"):
            try:
                project = self.gl.projects.get(project_id)

                # å–å¾— Commit åˆ—è¡¨
                params = {"per_page": 100}
                if start_date:
                    params["since"] = start_date
                if end_date:
                    params["until"] = end_date
                if ref_name:
                    params["ref_name"] = ref_name

                commits = project.commits.list(all=True, **params)

                for commit in commits:
                    commit_info = {
                        "project_id": project_id,
                        "commit_sha": commit.id,
                        "short_id": commit.short_id,
                        "title": commit.title,
                        "message": commit.message,
                        "author_name": commit.author_name,
                        "author_email": commit.author_email,
                        "authored_date": commit.authored_date,
                        "committer_name": commit.committer_name,
                        "committer_email": commit.committer_email,
                        "committed_date": commit.committed_date,
                        "created_at": commit.created_at,
                        "parent_ids": ",".join(commit.parent_ids) if commit.parent_ids else "",
                        "web_url": commit.web_url,
                    }

                    # çµ±è¨ˆè³‡è¨Š
                    stats = getattr(commit, "stats", {})
                    commit_info["additions"] = stats.get("additions", 0)
                    commit_info["deletions"] = stats.get("deletions", 0)
                    commit_info["total"] = stats.get("total", 0)

                    commit_data.append(commit_info)

                self._rate_limit_wait()

            except gitlab.exceptions.GitlabGetError as e:
                print(f"âš ï¸ ç„¡æ³•å­˜å–å°ˆæ¡ˆ {project_id}: {e}")
                continue
            except Exception as e:
                print(f"âš ï¸ è™•ç†å°ˆæ¡ˆ {project_id} çš„ Commits æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue

        # è½‰æ›ç‚º DataFrame
        df = pd.DataFrame(commit_data)

        # å„²å­˜åˆ° CSV
        output_file = self.output_dir / "gitlab_commits.csv"
        df.to_csv(output_file, index=False, encoding="utf-8-sig")
        print(f"âœ… Commit æ•¸æ“šå·²å„²å­˜: {output_file} (å…± {len(df)} ç­†)")

        return df

    # ==================== å®Œæ•´æ•¸æ“šæ”¶é›† ====================

    def collect_all(
        self,
        project_ids: Optional[List[int]] = None,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
    ) -> Dict[str, pd.DataFrame]:
        """
        æ”¶é›†æ‰€æœ‰æ•¸æ“šï¼ˆå°ˆæ¡ˆã€MRã€Commentsã€Commitsï¼‰

        Args:
            project_ids: å°ˆæ¡ˆ ID åˆ—è¡¨ï¼ŒNone è¡¨ç¤ºæ‰€æœ‰å°ˆæ¡ˆ
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ

        Returns:
            åŒ…å«æ‰€æœ‰æ•¸æ“šçš„å­—å…¸
        """
        print("=" * 60)
        print("é–‹å§‹æ”¶é›† GitLab æ•¸æ“š")
        print("=" * 60)

        results = {}

        # 1. æ”¶é›†å°ˆæ¡ˆåˆ—è¡¨
        if project_ids is None:
            projects_df = self.collect_projects()
            project_ids = projects_df["project_id"].tolist()
            results["projects"] = projects_df

        # 2. æ”¶é›† Merge Requests
        results["merge_requests"] = self.collect_merge_requests(
            project_ids=project_ids, start_date=start_date, end_date=end_date
        )

        # 3. æ”¶é›† Review Comments
        results["review_comments"] = self.collect_review_comments(
            project_ids=project_ids, start_date=start_date, end_date=end_date
        )

        # 4. æ”¶é›† Commits
        results["commits"] = self.collect_commits(
            project_ids=project_ids, start_date=start_date, end_date=end_date
        )

        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰æ•¸æ“šæ”¶é›†å®Œæˆï¼")
        print("=" * 60)
        print(f"å°ˆæ¡ˆæ•¸é‡: {len(results.get('projects', []))}")
        print(f"MR æ•¸é‡: {len(results['merge_requests'])}")
        print(f"Review Comments æ•¸é‡: {len(results['review_comments'])}")
        print(f"Commits æ•¸é‡: {len(results['commits'])}")
        print("=" * 60)

        return results


# æ¸¬è©¦åŠŸèƒ½ï¼ˆå¯ç¨ç«‹åŸ·è¡Œæ­¤æ¨¡çµ„æ¸¬è©¦ï¼‰
if __name__ == "__main__":
    import sys

    print("=" * 60)
    print("GitLab API æ•¸æ“šæ”¶é›†å™¨æ¸¬è©¦")
    print("=" * 60)

    collector = GitLabAPICollector()

    # æ¸¬è©¦ï¼šæ”¶é›†å°ˆæ¡ˆåˆ—è¡¨
    print("\næ¸¬è©¦ 1ï¼šæ”¶é›†å°ˆæ¡ˆåˆ—è¡¨ï¼ˆå‰ 5 å€‹ï¼‰")
    try:
        projects_df = collector.collect_projects()
        print(f"\næ”¶é›†åˆ° {len(projects_df)} å€‹å°ˆæ¡ˆ")
        if len(projects_df) > 0:
            print("\nå‰ 5 å€‹å°ˆæ¡ˆï¼š")
            print(projects_df.head()[["project_id", "name", "path_with_namespace"]])
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        sys.exit(1)

    print("\n" + "=" * 60)
    print("âœ… æ¸¬è©¦å®Œæˆ")
    print("=" * 60)
